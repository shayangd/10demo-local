# Interview Execution Guide - Recipe 1.1
## Problem Validation Interviews for 10Demo

**Generated**: 2025-01-02
**Target**: 10-15 customer discovery interviews
**Timeline**: 2-4 weeks
**Methodology**: The Mom Test

---

## Overview

### Venture Context

**Problem Statement**
B2B SaaS companies lose qualified leads due to demo scheduling friction. Prospects wait 42+ hours for generic demos that don't address their needs, while sales teams face 40-60% no-show rates and can't scale personalized demos without exploding headcount costs. The result: massive pipeline leakage from delays and poor demo experiences.

**Solution Statement**
10Demo is an AI agent that delivers live, voice-led product demos on video calls 24/7â€”responding in under 5 minutes and actually clicking through and controlling the product in real-time while conversing naturally with prospects. Unlike static demo videos or scripted tools, it combines real-time UI control with conversational AI and CRM integration to behave like a trained sales rep at infinite scale.

### Interview Goals

This interview guide will help you validate:

1. **Problem Severity**: Do prospects experience demo scheduling friction as a significant pain point?
2. **Problem Recency**: Is this an active, current problem (not theoretical)?
3. **Workarounds**: Are prospects actively trying to solve this (budget signal)?
4. **Solution Resonance**: Does the AI demo agent concept align with desired outcomes?
5. **Willingness to Pay**: Would they pay for this solution and at what price?

### Success Criteria (Recipe 1.1 KPIs)

- **I1.1**: Pain Intensity â‰¥7/10 (target: 10+ respondents)
- **I1.2**: Active Workarounds â‰¥70% of respondents
- **I1.3**: Recency â‰¥75% (problem within 30 days)
- **I1.4**: Solution Resonance â‰¥70% positive response
- **I1.5**: Competitive Displacement â‰¥60% would switch
- **I1.6**: Outcome Alignment â‰¥80% matches desired outcomes
- **I1.7**: Budget Existence â‰¥60% have budget
- **I1.8**: Purchase Intent â‰¥4/5 from â‰¥50% of respondents
- **I1.9**: Interview Completion Rate â‰¥80%
- **I1.10**: Van Westendorp pricing convergence

---

## Target Personas

### Persona 1: VP Sales / Head of Sales at Growth-Stage SaaS (SMB/Mid-Market)

**Segment**: Mid-Market
**Role**: VP Sales, Head of Sales, Sales Director
**Company Profile**:
- 50-500 employees
- $5M-$50M ARR
- 5-20 sales reps (AEs + SDRs)
- B2B SaaS product with demo-led sales motion
- Industries: Marketing tech, Sales tech, HR tech, DevOps tools

**Why Interview**: Primary buyer persona. Controls budget for sales enablement tools. Feels pain of demo friction directly through pipeline metrics.

**Interview Focus**:
- Demo scheduling delays and no-show rates (Q1-Q8)
- Sales rep headcount constraints (Q5-Q6)
- Current demo tools and costs (Q9-Q16, Q19-Q20)
- Budget authority and procurement process (Q17-Q27)

**Key Validation Questions**:
- What's their current cost per demo delivered?
- How many leads churn due to scheduling delays?
- What's sales team utilization vs. demo delivery capacity?

**Expected Distribution**: 5-6 interviews (40% of total)

---

### Persona 2: Sales Operations Manager at Mid-Market/Enterprise SaaS

**Segment**: Mid-Market to Enterprise
**Role**: Sales Operations Manager, Revenue Operations Manager
**Company Profile**:
- 200-2000 employees
- $20M-$200M ARR
- 20-100 sales reps
- Complex sales tech stack (Salesforce, Gong, Outreach, etc.)
- High-velocity or PLG-hybrid sales model

**Why Interview**: Influencer persona. Manages sales tools, tracks metrics, identifies bottlenecks. Has detailed data on demo conversion rates and scheduling friction.

**Interview Focus**:
- Demo funnel metrics and conversion data (Q3-Q4)
- Integration requirements (CRM, calendar, demo environment)
- Current workarounds and tool stack costs (Q11-Q13)
- ROI calculation methodology (Q18-Q20)

**Key Validation Questions**:
- What tools do they currently use for demo automation?
- What metrics do they track for demo effectiveness?
- What's the approval process for new sales tools?

**Expected Distribution**: 3-4 interviews (25% of total)

---

### Persona 3: Founder/CEO at Early-Stage SaaS (SMB)

**Segment**: SMB
**Role**: Founder, CEO (often hands-on with sales)
**Company Profile**:
- 5-50 employees
- $500K-$5M ARR
- 1-5 sales reps (or founder-led sales)
- Pre-Series A or Series A
- Often still doing demos personally

**Why Interview**: Economic buyer for early-stage companies. Feels pain acutely due to limited resources. Highly price-sensitive but willing to pay for force multipliers.

**Interview Focus**:
- Time spent on demos vs. other priorities (Q1-Q2)
- Scaling challenges without adding headcount (Q5-Q6)
- Budget constraints and ROI sensitivity (Q17-Q27)
- Speed of purchase decision (days, not months)

**Key Validation Questions**:
- How many hours per week do they personally spend on demos?
- What's preventing them from hiring more sales reps?
- What's their customer acquisition cost target?

**Expected Distribution**: 2-3 interviews (20% of total)

---

### Persona 4: Sales Enablement Director at Enterprise SaaS

**Segment**: Enterprise
**Role**: Sales Enablement Director, Director of Sales Development
**Company Profile**:
- 500+ employees
- $50M+ ARR
- 50+ sales reps
- Global teams, multiple time zones
- Standardized demo processes and training programs

**Why Interview**: Strategic buyer for large organizations. Faces scaling challenges but has budget. Validation here = large deal potential but longer sales cycles.

**Interview Focus**:
- Demo quality consistency across global teams (Q7-Q8)
- Training costs and time-to-productivity for new reps (Q6)
- Enterprise requirements (security, compliance, SSO) (Q14-Q16)
- Procurement process and budget cycles (Q18-Q20)

**Key Validation Questions**:
- What's the cost to train a new rep on product demos?
- How do they ensure demo quality across 50+ reps?
- What's their evaluation process for enterprise sales tools?

**Expected Distribution**: 2 interviews (15% of total)

---

## Recruitment Strategy

### Timeline

**Week 1**: Outreach and scheduling (aim for 10-15 confirmed meetings)
**Week 2-3**: Conduct interviews (2-3 per day max to avoid fatigue)
**Week 4**: Follow-ups, analysis, synthesis

### Recruitment Channels

#### 1. LinkedIn Outreach (Primary)

**Target Search**:
- Title: "VP Sales" OR "Head of Sales" OR "Sales Operations" OR "Revenue Operations"
- Industry: Computer Software, SaaS, Internet
- Company Size: 51-500 employees
- Geography: US, Canada, UK (English-speaking markets)

**Outreach Sequence**:
1. Connection request with note (see Template 1 below)
2. If accepted, send interview invitation (Template 2)
3. If no response in 3 days, follow-up (Template 3)

#### 2. Existing Network & Warm Introductions

- Reach out to founders and sales leaders you know
- Ask for intros to their VP Sales or Sales Ops counterparts
- Leverage advisor network, investors, accelerator alumni

#### 3. Communities & Slack Groups

- SaaStr community
- Sales Hacker Slack
- Pavilion (Revenue Collective)
- Indie Hackers (for founder persona)
- Post in relevant channels: "Researching demo scheduling challenges in B2B SaaSâ€”happy to share findings with anyone interested"

#### 4. Events & Conferences

- SaaStr conferences and local meetups
- Sales enablement meetups
- RevOps meetups
- Offer to share research findings in exchange for 30 min

### Outreach Templates

#### Template 1: LinkedIn Connection Request

```
Hi [Name],

I'm researching how B2B SaaS sales teams handle product demos and scheduling. Given your experience at [Company], I'd love to get your perspective.

Would you be open to a 30-min conversation? Happy to share what I'm learning.

Thanks,
[Your Name]
```

**Notes**: Keep it short (298 char limit). No pitch, no ask for "feedback on my idea."

---

#### Template 2: Interview Invitation (DM after connection)

```
Hey [Name],

Thanks for connecting! I'm doing customer research on demo scheduling and delivery challenges in B2B SaaS sales.

I'd love to hear about your experience:
- How your team currently handles demo requests
- Challenges with scheduling, no-shows, or scaling demos
- What tools or workarounds you've tried

This is pure researchâ€”no sales pitch. 30 minutes over Zoom, and I'll share my findings afterward. I'm especially interested in [specific aspect relevant to their company/role].

Do you have time next week? Here's my calendar: [calendar link]

Thanks,
[Your Name]
```

**Notes**: Emphasize "no pitch." Lead with curiosity. Mention you'll share findings (value exchange).

---

#### Template 3: Follow-Up (if no response in 3 days)

```
Hey [Name],

Following up on my note about demo scheduling research. I know you're busy, but I'd really value your insights given [specific reasonâ€”e.g., "your team's focus on product-led growth"].

If the timing's not right, no worriesâ€”any chance you could point me to someone else on your sales team who deals with demo logistics?

Thanks,
[Your Name]
```

**Notes**: Give them an out. Ask for referral if they can't participate.

---

#### Template 4: Warm Introduction Request (to mutual contact)

```
Hey [Mutual Contact],

Hope you're doing well! I'm doing some customer research on how B2B SaaS companies handle product demos, and I'm trying to talk to sales leaders who feel the pain of demo scheduling and scaling.

Do you know anyone at a SaaS company (ideally 50-500 people) who runs sales or sales ops? I'd love a quick introâ€”happy to share what I learn in case it's useful for [Mutual Contact's Company] too.

Thanks!
[Your Name]
```

---

### Incentives & Value Exchange

**What you're offering**:
1. **Share findings**: "I'll send you a summary of what I learn from 10+ sales leaders"
2. **Benchmark data**: "I'll share how other companies are solving this"
3. **Early access**: "If this turns into something, you'll be first to try it"
4. **Gift card** (optional): $25-$50 Amazon gift card for 30-min interview (use sparinglyâ€”can bias responses)

**What NOT to do**:
- Don't pitch your solution during recruitment
- Don't say "validate my startup idea"
- Don't use "feedback" language (implies you want validation)

---

### Scheduling Best Practices

- Use Calendly or SavvyCal (let them pick time)
- Default to 30 minutes (go to 45 if they're engaged)
- Send calendar invite with Zoom link immediately
- Reminder email 24 hours before with:
  - Zoom link
  - Agenda (reassure it's conversational, not a survey)
  - Your photo and LinkedIn (build trust)

---

## Interview Script (27 Questions)

### Overview

**Total Time**: 60 minutes (aim for 45-50)
**Your Talk Time**: 30% (listening 70%)
**Structure**: Chronological story of their experience, not Q&A survey

**Key Principles** (The Mom Test):
1. **Talk about their life, not your idea**
2. **Ask about specifics in the past, not hypotheticals**
3. **Listen more than you talk**

---

### Section 1: Problem Discovery (20 minutes)

**Goal**: Understand if demo scheduling friction is a real, severe, active problem.

---

#### Q1: Tell me about your current sales processâ€”how does a prospect go from initial interest to seeing a product demo?

**Purpose**: Understand their existing workflow and identify where friction exists.

**KPI Mapping**: Contextual (sets up Q2-Q8)

**Listen for**:
- Steps in their demo funnel (inbound lead â†’ SDR qual â†’ demo scheduled â†’ demo delivered)
- Who's involved (SDRs, AEs, Sales Engineers, founders)
- Current tools (Calendly, Chili Piper, manual scheduling)
- Tone of voice (frustrated? resigned? satisfied?)

**Probing Questions**:
- "Walk me through what happens after someone fills out the 'Request a Demo' form on your site."
- "How long does it typically take from request to demo delivered?"
- "Who on your team is responsible for scheduling and conducting demos?"

**Red Flags**:
- ðŸš© "We don't really do demos" (wrong ICP)
- ðŸš© "Our process is great, no issues" (not in pain)
- ðŸš© "We use [competitor product] and love it" (strong incumbent)

---

#### Q2: When was the last time you felt frustrated by how long it took to get a prospect into a demo?

**Purpose**: Establish recency and emotional intensity of the problem.

**KPI Mapping**: I1.3 (Recency), I1.1 (Pain Intensityâ€”indirectly)

**Listen for**:
- Specific date or timeframe ("last week," "yesterday," "this morning")
- Emotional language ("we lost the deal," "prospect went cold," "unacceptable")
- Concrete example (not "this happens all the time" but "last Tuesday...")

**Probing Questions**:
- "What happened? Tell me the story."
- "How did you find out about the delay?"
- "What was the outcomeâ€”did you win or lose the deal?"
- "How often does this happen?"

**Red Flags**:
- ðŸš© "I can't remember" (not a frequent/painful problem)
- ðŸš© "It's not really an issue" (no pain)
- ðŸš© "We solved that years ago" (problem is solved)

---

#### Q3: How many demo requests do you get per week, and what percentage of those actually convert to completed demos?

**Purpose**: Quantify funnel leakage and no-show rates.

**KPI Mapping**: I1.1 (Pain Intensityâ€”higher leakage = higher pain), Contextual

**Listen for**:
- Raw numbers (e.g., "100 requests â†’ 60 scheduled â†’ 35 completed")
- Awareness of the problem ("yeah, our no-show rate is terribleâ€”40%")
- Whether they track this metric (if not, probe for estimates)

**Probing Questions**:
- "What happens to the other [X]%? Where do they drop off?"
- "What's your no-show rate?"
- "Do you track this in Salesforce or another system?"
- "How does that compare to your target conversion rate?"

**Red Flags**:
- ðŸš© "We have a 90% show rate" (no problem)
- ðŸš© "I don't know, we don't track that" (not measured = not important)

---

#### Q4: On a scale of 0-10, how much of a problem is demo scheduling and delivery friction for your team? (0 = no problem, 10 = critical)

**Purpose**: Explicitly measure pain intensity.

**KPI Mapping**: I1.1 (Pain Intensity)

**Listen for**:
- Score â‰¥7 = strong pain
- Score 4-6 = moderate pain (conditional)
- Score <4 = weak pain (no-go)
- Unprompted justification ("it's an 8 because we lose 30% of pipeline")

**Probing Questions**:
- "Why that number?"
- "What would make it a 10?"
- "What would make it a 0?"
- "How does this compare to other problems your sales team faces?"

**Red Flags**:
- ðŸš© Score <5 (not painful enough)
- ðŸš© "I guess... maybe a 6?" (wishy-washy = not painful)

---

#### Q5: What have you tried to solve this problem?

**Purpose**: Identify active workarounds (budget signal) and learn about competitive landscape.

**KPI Mapping**: I1.2 (Active Workarounds), Competitive landscape

**Listen for**:
- Paid tools (Chili Piper, Calendly, demo automation platforms)
- Internal solutions (hiring more SDRs/AEs, pre-recorded demos)
- DIY workarounds (macros, Loom videos, FAQ pages)
- Spending money or time = strong signal

**Probing Questions**:
- "How much do those solutions cost?"
- "How well do they work?"
- "What's still broken after using them?"
- "Why did you stop using [X]?"

**Red Flags**:
- ðŸš© "Nothing, we just deal with it" (no urgency)
- ðŸš© "We tried [competitor] and it solved everything" (problem is solved)

---

#### Q6: How much time do your sales reps spend on demos per week? Is that time well spent, or does it prevent them from doing other things?

**Purpose**: Understand opportunity cost and scaling constraints.

**KPI Mapping**: I1.1 (Pain Intensity), Contextual

**Listen for**:
- Hours per week per rep (e.g., "each AE does 10-15 demos/week = 10-15 hours")
- Opportunity cost ("they could be closing deals instead")
- Scaling pain ("we'd need to hire 5 more reps to handle demand")

**Probing Questions**:
- "How many demos does each rep do per day/week?"
- "What else could they be doing with that time?"
- "What happens if demo requests spikeâ€”say, after a marketing campaign?"

**Red Flags**:
- ðŸš© "Demos are their primary job, so it's fine" (no opportunity cost)
- ðŸš© "We have plenty of capacity" (no scaling constraint)

---

#### Q7: Tell me about a time when a demo didn't go well because it wasn't personalized or relevant to the prospect.

**Purpose**: Validate the "generic demo" pain point.

**KPI Mapping**: I1.1 (Pain Intensityâ€”contributes to problem severity)

**Listen for**:
- Specific story ("last month, we demoed the wrong features to a healthcare prospect")
- Lost deal or delayed close
- Prospect feedback ("they said it wasn't relevant")

**Probing Questions**:
- "What happened after that demo?"
- "How often does this happen?"
- "What causes demos to be generic vs. personalized?"
- "How do you train reps to personalize demos?"

**Red Flags**:
- ðŸš© "Our demos are always personalized" (no pain point)
- ðŸš© "Prospects don't care, they just want to see the product" (wrong ICP)

---

#### Q8: If you could wave a magic wand and fix one thing about your demo process, what would it be?

**Purpose**: Discover top-of-mind pain (not leading with your solution).

**KPI Mapping**: Solution-Problem Fit (informs I1.4-I1.6)

**Listen for**:
- What they say first = highest priority pain
- Alignment with your solution (instant demos, personalization, 24/7 availability)
- Other pain points you hadn't considered

**Probing Questions**:
- "Why that one specifically?"
- "What would that enable you to do that you can't do now?"
- "How much would solving that be worth to you?"

**Red Flags**:
- ðŸš© Answers something unrelated to your solution (e.g., "better lead scoring")
- ðŸš© "Nothing, honestly" (no pain)

---

### Section 2: Solution Exploration (20 minutes)

**Goal**: Present the solution concept and assess resonance without pitching.

**Transition**: "Thanks for sharing all that. Based on what you've said, I want to describe a potential solution and get your reactionâ€”not to pitch you, but to understand if it would actually solve the problems you've mentioned."

---

#### Q9: [Present Solution Concept] We're exploring an AI agent that delivers live, voice-led product demos 24/7. It responds in under 5 minutes, clicks through your actual product in real-time, and has natural conversations with prospectsâ€”like a trained sales rep, but infinitely scalable. What's your initial reaction?

**Purpose**: Gauge solution resonance and identify concerns.

**KPI Mapping**: I1.4 (Solution Resonance)

**Listen for**:
- Positive reaction ("that would be amazing," "we need this")
- Skepticism ("how would it handle X?" = engaged but needs proof)
- Confusion ("I don't get it" = messaging issue)
- Immediate objections ("our prospects would never talk to a bot")

**Probing Questions**:
- "What do you like about it?"
- "What concerns you?"
- "How would this fit into your current sales process?"
- "What would need to be true for you to use this?"

**Red Flags**:
- ðŸš© "That's a nice-to-have, not a must-have"
- ðŸš© "We'd never use AI for demos" (fundamental objection)
- ðŸš© "Sounds like [competitor]" (commoditized)

---

#### Q10: How does this compare to what you're using today?

**Purpose**: Understand competitive displacement.

**KPI Mapping**: I1.5 (Competitive Displacement)

**Listen for**:
- "This solves [X] that [current tool] doesn't"
- "We'd replace [current tool] immediately"
- "This would complement [current tool]"
- Switching costs and friction

**Probing Questions**:
- "Would this replace something you're using, or add to your stack?"
- "What would make you switch from [current tool] to this?"
- "What would prevent you from switching?"

**Red Flags**:
- ðŸš© "We'd never switch from [incumbent]" (strong lock-in)
- ðŸš© "We'd use both, I guess" (unclear value prop)

---

#### Q11: What concerns or objections come to mind about using an AI agent for demos?

**Purpose**: Surface objections early (pricing, trust, quality, integration).

**KPI Mapping**: Solution Feasibility (informs product roadmap, not a KPI per se)

**Listen for**:
- Trust ("would prospects know it's AI?")
- Quality ("can it handle complex questions?")
- Control ("how do we ensure it doesn't say the wrong thing?")
- Integration ("does it work with Salesforce?")

**Probing Questions**:
- "Which of these concerns is the biggest blocker?"
- "What would need to happen to overcome that concern?"
- "Have you used AI tools in sales before? How'd that go?"

**Red Flags**:
- ðŸš© Fundamental, non-addressable objections (e.g., "AI is unethical")
- ðŸš© Long list of concerns with no prioritization (not serious buyer)

---

#### Q12: If this existed today, how would you want to use it? Walk me through a scenario.

**Purpose**: Validate use cases and identify feature requirements.

**KPI Mapping**: I1.6 (Outcome Alignment)

**Listen for**:
- Specific use case ("we'd use it for inbound SMB leads")
- Integration points ("it would pull data from Salesforce")
- Success metrics ("we'd measure conversion rate and time-to-demo")
- Role in workflow (replaces humans vs. augments them)

**Probing Questions**:
- "Who on your team would set this up?"
- "How would you train it on your product?"
- "What would success look like after 30 days?"

**Red Flags**:
- ðŸš© Vague answer ("I don't know, we'd figure it out")
- ðŸš© Use case doesn't align with your solution (e.g., "we'd use it for customer support")

---

#### Q13: What would need to be true about the quality of the AI demos for you to trust it with your prospects?

**Purpose**: Understand quality bar and risk tolerance.

**KPI Mapping**: I1.6 (Outcome Alignment)

**Listen for**:
- Quality bar ("it needs to be 90% as good as our best rep")
- Risk tolerance ("we'd test it on low-value leads first")
- Control mechanisms ("we need to review transcripts and override")

**Probing Questions**:
- "How do you currently ensure demo quality with human reps?"
- "What's the worst thing that could happen if a demo goes wrong?"
- "Would you be willing to pilot this with a subset of leads?"

**Red Flags**:
- ðŸš© "It has to be perfect" (unrealistic expectations)
- ðŸš© "We can't risk any bad demos" (not risk-tolerant enough for early adopter)

---

#### Q14: How important is it that the AI agent integrates with your CRM and other sales tools?

**Purpose**: Understand integration requirements (MVP vs. nice-to-have).

**KPI Mapping**: Product Requirements (not a go/no-go KPI, but informs roadmap)

**Listen for**:
- "Must-have" vs. "nice-to-have"
- Which integrations matter most (Salesforce, HubSpot, Outreach, Gong)
- Workflow dependencies ("if it doesn't log to Salesforce, we can't use it")

**Probing Questions**:
- "What tools does your sales team use daily?"
- "What data would the AI need to access to deliver a good demo?"
- "Would you use it if it didn't integrate at first, but logged data manually?"

**Red Flags**:
- ðŸš© "We need 10+ integrations on day one" (too complex for MVP)
- ðŸš© "Integration doesn't matter" (not a serious buyer)

---

#### Q15: If this saved your team [X hours per week] or [Y% more demos delivered], what would that enable you to do?

**Purpose**: Quantify value and understand desired outcomes.

**KPI Mapping**: I1.6 (Outcome Alignment)

**Listen for**:
- Specific outcomes ("we'd close 20% more deals," "we'd expand to a new market")
- Dollar value ("that's worth $500K/year in revenue")
- Strategic impact ("we could go upmarket without hiring 10 more reps")

**Probing Questions**:
- "How much revenue does each additional demo convert to?"
- "What's the cost of hiring another sales rep vs. using this?"
- "What's the business impact of delivering demos 24/7 vs. 9-5?"

**Red Flags**:
- ðŸš© "Not sure, honestly" (can't articulate value)
- ðŸš© "We'd just use the extra capacity for other things" (no clear ROI)

---

#### Q16: On a scale of 1-5, how likely are you to use a solution like this if it existed today? (1 = not at all, 5 = definitely)

**Purpose**: Explicit solution resonance measure.

**KPI Mapping**: I1.4 (Solution Resonance), I1.8 (Purchase Intentâ€”initial gauge)

**Listen for**:
- Score â‰¥4 = strong interest
- Score 3 = conditional interest
- Score â‰¤2 = weak interest
- Unprompted caveats ("5, but only if it costs less than $X")

**Probing Questions**:
- "Why that number?"
- "What would make it a 5?"
- "What would make it a 1?"

**Red Flags**:
- ðŸš© Score â‰¤2 (not interested)
- ðŸš© "Maybe a 3?" (wishy-washy)

---

### Section 3: Willingness to Pay (20 minutes)

**Goal**: Understand budget, current spend, and pricing expectations.

**Transition**: "I want to shift gears and talk about the business sideâ€”not to sell you anything, but to understand what you're currently spending and what you'd expect to pay for something like this."

---

#### Q17: Do you currently have budget allocated for sales tools or demo automation?

**Purpose**: Establish budget existence.

**KPI Mapping**: I1.7 (Budget Existence)

**Listen for**:
- "Yes, we have $X/year for sales tools"
- "No, but we could find budget if the ROI is clear"
- "We just renewed [incumbent], so no budget until next year"
- Budget owner and approval process

**Probing Questions**:
- "Who controls that budget?"
- "How much is allocated annually?"
- "When does your budget cycle reset?"
- "What's the approval process for a new tool?"

**Red Flags**:
- ðŸš© "We have zero budget" (not a near-term buyer)
- ðŸš© "Budget is frozen for 12 months" (timing issue)

---

#### Q18: How much do you currently spend on demo scheduling and delivery? (Include tools, headcount, opportunity cost)

**Purpose**: Understand current spend and establish willingness to pay anchor.

**KPI Mapping**: I1.7 (Budget Existence), I1.10 (Van Westendorp pricingâ€”anchor)

**Listen for**:
- Tool costs (Chili Piper, Calendly, demo platforms)
- Headcount costs (e.g., "3 AEs spend 50% time on demos = $150K/year")
- Opportunity cost ("we could close 20% more deals if reps spent less time on demos")

**Probing Questions**:
- "Walk me through all the costsâ€”tools, people, time, lost deals."
- "How much do you spend per demo delivered?"
- "What's the fully-loaded cost of a sales rep doing demos?"

**Red Flags**:
- ðŸš© "I have no idea" (doesn't think about cost)
- ðŸš© "We spend almost nothing" (low willingness to pay)

---

#### Q19: If you had to guess, how much would you expect a solution like this to cost per month?

**Purpose**: Gut-check pricing expectations (open-ended).

**KPI Mapping**: I1.10 (Van Westendorp pricingâ€”initial anchor)

**Listen for**:
- Dollar amount ("probably $500-$1,000/month")
- Pricing model assumptions (per-seat, per-demo, flat-rate, usage-based)
- Comparison to incumbents ("probably similar to Chili Piper")

**Probing Questions**:
- "Why that number?"
- "How did you arrive at that?"
- "Would you expect to pay per seat, per demo, or a flat fee?"

**Red Flags**:
- ðŸš© "$50/month" (way too lowâ€”wrong segment)
- ðŸš© "$50K/year" (way too highâ€”misunderstood solution)

---

#### Q20: How do you typically evaluate ROI for sales tools? What metrics matter most?

**Purpose**: Understand decision criteria and evaluation process.

**KPI Mapping**: I1.6 (Outcome Alignment), I1.8 (Purchase Intent)

**Listen for**:
- Key metrics (cost per demo, conversion rate, time-to-demo, CAC)
- ROI threshold ("needs to pay for itself in 6 months")
- Evaluation process (trial, pilot, RFP, procurement)

**Probing Questions**:
- "What's the last sales tool you bought? How did you evaluate it?"
- "What ROI threshold do you need to see to approve a purchase?"
- "How long does procurement typically take?"

**Red Flags**:
- ðŸš© "We don't really evaluate ROI" (not rigorous buyer)
- ðŸš© "We need 18-month contracts and enterprise security review" (too slow for MVP)

---

### Van Westendorp Pricing Sequence (Q21-Q24)

**Context**: "I'm going to ask you four quick pricing questions to understand what you'd expect to pay. There are no right or wrong answersâ€”just your gut reaction."

---

#### Q21: At what price would you consider this solution to be so expensive that you would not consider buying it? (Too expensive)

**Purpose**: Van Westendorp - identify price ceiling.

**KPI Mapping**: I1.10 (Van Westendorp pricing)

**Listen for**:
- Dollar amount
- Rationale ("above $X, I'd just hire another rep")

**Probing Questions**:
- "Why that number?"
- "What's the alternative if it costs more than that?"

---

#### Q22: At what price would you consider this solution to be priced so low that you would feel the quality couldn't be very good? (Too cheap)

**Purpose**: Van Westendorp - identify price floor.

**KPI Mapping**: I1.10 (Van Westendorp pricing)

**Listen for**:
- Dollar amount
- Rationale ("below $X, I'd worry it's a toy or won't work")

**Probing Questions**:
- "Why that number?"
- "What quality concerns would you have at that price?"

---

#### Q23: At what price would you consider this solution starting to get expensive, but you'd still consider buying it? (Expensive but acceptable)

**Purpose**: Van Westendorp - identify upper willingness to pay.

**KPI Mapping**: I1.10 (Van Westendorp pricing)

**Listen for**:
- Dollar amount
- Rationale ("at $X, I'd need to see strong ROI proof")

---

#### Q24: At what price would you consider this solution to be a bargainâ€”a great buy for the money? (Great value)

**Purpose**: Van Westendorp - identify lower willingness to pay.

**KPI Mapping**: I1.10 (Van Westendorp pricing)

**Listen for**:
- Dollar amount
- Rationale ("at $X, I'd buy immediately without much evaluation")

---

#### Q25: If this launched next month at [Optimal Price Point from Q21-Q24], how likely would you be to buy it? (1 = not likely, 5 = very likely)

**Purpose**: Measure purchase intent.

**KPI Mapping**: I1.8 (Purchase Intent)

**Listen for**:
- Score â‰¥4 = strong intent
- Score 3 = conditional intent
- Score â‰¤2 = weak intent
- Caveats ("5, but only after we see a demo ourselves")

**Probing Questions**:
- "Why that number?"
- "What would make you more likely to buy?"
- "What would prevent you from buying?"
- "What would the evaluation/approval process look like?"

**Red Flags**:
- ðŸš© Score â‰¤2 (not a buyer)
- ðŸš© "I'd need to talk to 5 other stakeholders first" (too slow for early adopter)

---

#### Q26: If we gave you early access in the next 30 days, would you be willing to pilot this with a subset of your leads?

**Purpose**: Test commitment and identify early adopters.

**KPI Mapping**: I1.8 (Purchase Intentâ€”behavioral commitment)

**Listen for**:
- "Yes, absolutely" (strong signal)
- "Yes, but [condition]" (conditional signal)
- "Let me think about it" (weak signal)
- "No" (not an early adopter)

**Probing Questions**:
- "What would you need to see in a pilot to move forward?"
- "How many leads would you be willing to test it with?"
- "What success metrics would you track?"
- "Who else would need to approve a pilot?"

**Red Flags**:
- ðŸš© "Maybe in 6 months" (not urgent)
- ðŸš© "We'd need a full security audit first" (too slow for MVP)

---

#### Q27: Who else should I talk to on your team or in your network who deals with this problem?

**Purpose**: Referral for snowball sampling.

**KPI Mapping**: None (recruitment strategy)

**Listen for**:
- Names and intros
- "Talk to our VP Sales / Sales Ops lead"
- "You should talk to [peer at another company]"

**Probing Questions**:
- "Would you mind making an intro?"
- "What should I know about their situation before reaching out?"

---

### Closing the Interview

**Wrap-up** (2 minutes):

1. **Thank them**: "This has been incredibly helpful. Thank you for your time."
2. **Recap**: "Just to summarize what I heard: [2-3 key takeaways]."
3. **Next steps**: "I'll send you a summary of what I learn from all these conversations. If we decide to build this, you'll be first to know."
4. **Ask for referral** (Q27 if not already asked)
5. **Send thank-you email within 24 hours** with:
   - Summary of their key points
   - Timeline for sharing findings
   - Calendar hold for follow-up (optional)

---

## The Mom Test Reminders

### During the Interview

**DO**:
- âœ… Ask about specific past events ("tell me about the last time...")
- âœ… Listen 70%, talk 30%
- âœ… Ask follow-up questions ("why?" "tell me more")
- âœ… Take notes (but not so much that you stop listening)
- âœ… Let silence happen (don't rush to fill it)

**DON'T**:
- âŒ Pitch your solution (except in Section 2, and even then, neutrally)
- âŒ Ask hypothetical questions ("would you use...?")
- âŒ Lead the witness ("don't you think this is a big problem?")
- âŒ Seek validation ("do you like my idea?")
- âŒ Talk about features (talk about problems and outcomes)

### Red Flags to Listen For

- **Compliments**: "That's a great idea!" = politeness, not commitment
- **Hypotheticals**: "I would definitely use this" = not a real commitment
- **Generic statements**: "This is a problem for everyone" = not personal experience
- **Future tense**: "We're planning to solve this next year" = not urgent

### Green Flags to Listen For

- **Specifics**: "Last Tuesday, we lost a $50K deal because..."
- **Pain intensity**: Emotional language, frustration, urgency
- **Time spent**: "I spend 10 hours/week on this"
- **Money spent**: "We pay $X/month for [workaround]"
- **Commitment**: "If you build this, I'll pilot it next month"

---

## After the Interview

### Immediate Next Steps (within 1 hour)

1. **Write up notes**: Expand on shorthand while memory is fresh
2. **Tag key quotes**: Flag exact words for pain intensity, objections, pricing
3. **Score the interview**:
   - Pain intensity (0-10)
   - Solution interest (1-5)
   - Purchase intent (1-5)
   - Persona fit (correct ICP? yes/no)
4. **Update tracking spreadsheet** (see template below)

### Follow-Up (within 24 hours)

Send thank-you email:

```
Subject: Thanks for your timeâ€”[Their Company] demo insights

Hi [Name],

Thank you for taking the time to talk with me today about how [Their Company] handles product demos. Your insights on [specific pain point they mentioned] were especially helpful.

A few key things I heard:
- [Takeaway 1]
- [Takeaway 2]
- [Takeaway 3]

I'll be wrapping up these interviews in the next 2 weeks and will send you a summary of what I learned. If you think of anything else or have follow-up thoughts, feel free to reply to this email.

Thanks again,
[Your Name]

P.S. If you know anyone else who deals with demo scheduling challenges, I'd love an intro!
```

---

## Interview Tracking Template

Use the template below to track interview responses. This will feed into your Recipe 1.1 analysis.

**Location**: See `interview-tracking-template.md` in the same directory.

---

## Appendix: Common Objections & Responses

### "Our prospects would never talk to an AI."

**Listen for**: Is this based on data or assumption?

**Follow-up**: "Have you tried AI tools in sales before? What happened?" / "What if prospects didn't know it was AI unless they asked?"

---

### "This is too expensive."

**Listen for**: Compared to what?

**Follow-up**: "What are you comparing it to?" / "What would make the ROI clear?" / "How much do you currently spend to deliver demos?"

---

### "We need to see it in action first."

**This is a good sign!** (Interest, but needs proof)

**Follow-up**: "What would you need to see in a demo to feel confident?" / "Would you be willing to pilot it with a subset of leads?"

---

### "We just signed a contract with [competitor]."

**Listen for**: Satisfaction with incumbent or buyer's remorse?

**Follow-up**: "How's that going?" / "What made you choose them?" / "What would make you switch when the contract is up?"

---

### "I need to talk to my team / get approval / run this by legal."

**Listen for**: Is this a real blocker or a polite no?

**Follow-up**: "Who else needs to be involved?" / "What's the approval process?" / "If it were up to you, would you move forward?"

---

## Next Steps After Completing 10-15 Interviews

1. **Aggregate data** using the tracking template
2. **Calculate KPIs** (I1.1-I1.10) per Recipe 1.1 specification
3. **Synthesize insights**:
   - Recurring pain points
   - Common objections
   - Pricing convergence (Van Westendorp analysis)
   - Persona fit (which personas have highest pain/purchase intent?)
4. **Decide**: GO / CONDITIONAL / NO-GO
5. **If GO**: Proceed to MVP scoping and pricing strategy
6. **If CONDITIONAL**: Iterate on ICP or solution positioning
7. **If NO-GO**: Pivot or kill idea

---

**End of Interview Execution Guide**
